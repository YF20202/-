'''
@author: Yifan Zhu
@e-mail: mayz0571@qq.com
'''
import pandas as pd
import csv
import networkx as nx
from networkx.algorithms import bipartite
import os
import numpy as np
from scipy.optimize import curve_fit

#构建初始海运网络
def foundnetwork():
    df = pd.read_csv("data/2015old edge and distance.csv", encoding='utf_8_sig',names=['port1', 'country1', 'lat1', 'lng1', 'port2', 'country2','lat2', 'lng2', 'GC'])
    G2015 = nx.Graph()
    for index, row in df.iterrows():
        G2015.add_edge(row[0], row[4], weight=row[8]) #权重为真实海运距离

    print("nodes:", G2015.nodes())  # 输出全部的节点
    print("edges:", G2015.edges())  # 输出全部的边
    print("number of nodes:", G2015.number_of_nodes())  # 输出边的数量
    print("number of edges:", G2015.number_of_edges())  # 输出边的数量
    return G2015

def mkdir(path):
  path=path.strip()
  path=path.rstrip("\\")

  isExists=os.path.exists(path)

  if not isExists:
    print(path+' success')
    os.makedirs(path)
    return True
  else:
    print(path+' have already existed')
    return False

#gc of each p and alpha
def mean_gc():
    ps = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]
    bs = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]  # 0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1
    seed = range(1, 30)
    res = pd.read_csv("expected output/results/result seed=" + str(0) + " p=" + str(0) + " b=" + str(0) + ".csv")
    res = res[['port']]
    for p in ps:
        for b in bs:
            df=pd.read_csv("expected output/results/result seed=" + str(0) + " p=" + str(p) + " b=" + str(b) + ".csv")
            df=df[['port', 'Termination len(largest_components)']]
            for s in seed:
                df1=pd.read_csv("expected output/results/result seed=" + str(s) + " p=" + str(p) + " b=" + str(b) + ".csv")
                df['Termination len(largest_components)'] = df['Termination len(largest_components)']+df1['Termination len(largest_components)']
            df['p='+str(p)+' b='+str(b)]=df['Termination len(largest_components)']/30
            df.drop(['Termination len(largest_components)'], axis=1,inplace=True)
            res=pd.merge(res,df,on='port',how='left')
    res.to_csv('expected output/results/final largest gaint component.csv')


def stp_after():
    G=foundnetwork()
    distance=pd.read_csv('data/2015 all port distance.csv')
    initial=pd.DataFrame(nx.all_pairs_shortest_path_length(G),columns=['port1','dict'])
    initial_weight=pd.DataFrame(nx.all_pairs_dijkstra_path_length(G,weight='weight'),columns=['port1','dict'])
    initial=initial.drop('dict', 1).assign(**pd.DataFrame(initial.dict.values.tolist()))
    initial=initial.set_index('port1')
    initial=initial.stack()
    initial=initial.reset_index().rename(columns={'level_1': 'port2',0:'stp_initial'})
    initial_weight=initial_weight.drop('dict', 1).assign(**pd.DataFrame(initial_weight.dict.values.tolist()))
    initial_weight=initial_weight.set_index('port1')
    initial_weight=initial_weight.stack()
    initial_weight=initial_weight.reset_index().rename(columns={'level_1': 'port2',0:'stp_initial_weight'})
    initial_weight = pd.merge(distance, initial_weight, how='left', on=['port1', 'port2'])
    initial = pd.merge(initial_weight,initial,  how='left', on=['port1', 'port2'])
    initial['1/stp_initial']=1/initial['stp_initial']
    initial['GC/stp_initial_weight']=initial['GC']/initial['stp_initial_weight']
    print(initial.groupby(by=['port1'],as_index=False)['1/stp_initial','GC/stp_initial_weight'].sum())
    ps = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]
    bs = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]
    s = 0
    i=0
    for p in ps:
        for b in bs:
            for s in range(10):
                for u in G.nodes():
                    i+=1
                    if(i>0):
                        node = []
                        print(s,p,b)
                        df=pd.read_csv('expected output/results/seed='+str(s)+' p='+str(p)+' b='+str(b)+ "/b " + u + ".csv")
                        mkdir("expected output/results/efficiency seed=" + str(s) + " p=" + str(p) + " b=" + str(b))
                        if(len(df)!=0):#如果网络中还有边
                            Gtmp=nx.Graph()
                            Gtmp.add_nodes_from(range(1, 1623), bipartite=0)
                            Gtmp.add_nodes_from(G.nodes(), bipartite=1)
                            for index, row in df.iterrows():
                                Gtmp.add_edge(row[0], row[1])
                            Gm = bipartite.project(Gtmp, G.nodes())
                            result=pd.DataFrame(nx.all_pairs_shortest_path_length(Gm), columns=['port1', 'dict'])
                            edge=pd.DataFrame(Gm.edges(),columns=['port1', 'port2'])
                            edge=pd.merge(edge,distance,how='left', on=['port1', 'port2'])
                            Gm=nx.from_pandas_edgelist(edge,'port1','port2','GC')
                            print(Gm.number_of_edges())
                            result_weight=pd.DataFrame(nx.all_pairs_dijkstra_path_length(Gm,weight='GC'),columns=['port1','dict'])
                            result = result.drop('dict', 1).assign(**pd.DataFrame(result.dict.values.tolist()))
                            result = result.set_index('port1')
                            result = result.stack()
                            result = result.reset_index().rename(columns={'level_1': 'port2', 0: 'stp'})
                            result_weight=result_weight.drop('dict', 1).assign(**pd.DataFrame(result_weight.dict.values.tolist()))
                            result_weight = result_weight.set_index('port1')
                            result_weight = result_weight.stack()
                            result_weight = result_weight.reset_index().rename(columns={'level_1': 'port2', 0: 'stp_weight'})
                            result = result[result['stp'] != 0]
                            result=pd.merge(result,result_weight,how='left',on=['port1','port2'])
                            result = pd.merge(result, initial, how='left', on=['port1', 'port2'])
                            result['1/stp']=1/result['stp']
                            result['GC/stp_weight'] = result['GC'] / result['stp_weight']
                            dict={'port':u,'effeciency':result['1/stp'].sum(),'effeciency_weight':result['GC/stp_weight'].sum(),'seed':s}
                            node.append(dict)
                            group=result.groupby(by=['port1'],as_index=False)['1/stp_initial','1/stp','GC/stp_initial_weight','GC/stp_weight'].sum()
                            group['delta E']=group['1/stp_initial']-group['1/stp']
                            group['delta E weight'] = group['GC/stp_initial_weight'] - group['GC/stp_weight']
                            group.to_csv('output/efficiency seed=' + str(s) + ' p=' + str(p) + ' b=' + str(b) + "/efficiency of alive node after cascading of " + u + ".csv",index=False)
                            result.loc[result['port1'] >= result['port2'], 'flag'] = result['port1'] + result['port2']
                            result.loc[result['port1'] < result['port2'], 'flag'] = result['port2'] + result['port1']
                            result = result.drop_duplicates(subset=['flag'])
                            result.drop(['flag','country1','ISO3_1','lat1','lng1','country2','ISO3_2','lat2','lng2','1/stp_initial','GC/stp_initial_weight','1/stp','GC/stp_weight'], inplace=True, axis=1)
                            result.to_csv('output/efficiency seed=' + str(s) + ' p=' + str(p) + ' b=' + str(
                                b) + "/shortest path length " + u + ".csv", index=False)
                        else:#如果网络中没有边
                            result=pd.DataFrame()
                            dict = {'port': u, 'effeciency': 0,'effeciency_weight': 0,'seed':s}
                            node.append(dict)
                            result.to_csv('expected output/results//efficiency seed=' + str(s) + ' p=' + str(p) + ' b=' + str(b) + "/网络崩溃 " + u + ".csv",index=False)
                        pd.DataFrame(node).to_csv('expected output/results//final efficiency p=' + str(p) + ' b=' + str(b) + "seed="+str(s)+".csv",index=False,mode='a+',header=0)

def efficiency_after():
    G=foundnetwork()
    initial=pd.read_csv('data/each port of delete one node initial efficiency.csv',names=['port1','efficiency','apart node'])
    initial_w=pd.read_csv('data/each port of delete one node initial weightefficiency.csv',names=['port1','efficiency','apart node'])
    ps = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]
    bs = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]
    seed = range(0,30)
    for p in ps:
        for b in bs:
            for u in G.nodes():
                ei=initial[initial['apart node']==u]
                wei = initial_w[initial_w['apart node'] == u]
                ei['efficiency after']=0
                wei['efficiency after'] = 0
                for s in seed:
                    if(os.path.exists('expected output/results/efficiency seed=' + str(s) + ' p=' + str(p) + ' b=' + str(b) + "/shortest path length " + u + ".csv")):
                        df=pd.read_csv('expected output/results/efficiency seed=' + str(s) + ' p=' + str(p) + ' b=' + str(b) + "/efficiency of alive node after cascading of " + u + ".csv")
                        ei=pd.merge(ei,df,on='port1',how='left')
                        wei = pd.merge(wei, df, on='port1', how='left')
                        ei=ei.fillna(0)
                        wei = wei.fillna(0)
                        if '1/stp' in ei.columns:
                            ei['efficiency after'] = ei['efficiency after']+ei['1/stp']
                            ei.drop(columns=['1/stp', '1/stp_initial','GC/stp_initial_weight','GC/stp_weight', 'delta E', 'delta E weight'], axis=1, inplace=True)
                        if 'GC/stp_weight' in wei.columns:
                            wei['efficiency after'] = wei['efficiency after'] + wei['GC/stp_weight']
                            wei.drop(columns=['1/stp', '1/stp_initial','GC/stp_initial_weight', 'GC/stp_weight', 'delta E', 'delta E weight'], axis=1,inplace=True)

                ei['efficiency after']=ei['efficiency after']/30
                wei['efficiency after']=wei['efficiency after']/30
                print(ei)
                print(wei)
                ei.to_csv('expected output/results/Figure11_12_A3/efficiency change after cascading p='+str(p)+' b='+str(b)+'.csv',mode='a+',header=0,index=False)
                wei.to_csv('expected output/results/Figure11_12_A3/weight efficiency change after cascading p='+str(p)+' b='+str(b)+'.csv', mode='a+', header=0,index=False)

def network_efficiency():
    G = foundnetwork()

    ps = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]
    bs = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]
    seed = range(0, 30)

    for p in ps:
        for b in bs:
            with open(
                    "expected output/results/Figure10/network efficiency p=" + str(p) + " b=" + str(b) + ".csv",
                    'a+', encoding='utf-8', newline='') as fw2:
                writer = csv.writer(fw2)
                writer.writerow(['node', 'efficiency', 'weight efficiency'])
            for u in G.nodes():
                eff = 0
                we = 0
                for s in seed:
                    if (os.path.exists('expected output/results/efficiency seed=' + str(s) + ' p=' + str(p) + ' b=' + str(b) + "/shortest path length " + u + ".csv")):
                        df = pd.read_csv('expected output/results/efficiency seed=' + str(s) + ' p=' + str(p) + ' b=' + str(b) + "/shortest path length " + u + ".csv")
                        eff+=2*sum(1/df['stp'])
                        we+=2*sum(df['GC']/df['stp_weight'])

                eff=eff/30
                we=we/30
                print([u,eff,we])
                with open(

                        "expected output/results/Figure10/network efficiency p=" + str(p) + " b=" + str(b) + ".csv",
                        'a+', encoding='utf-8', newline='') as fw2:
                    writer = csv.writer(fw2)
                    writer.writerow([u,eff,we])

def start_up():
    stp_after()
    efficiency_after()
    ps = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]
    bs = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]
    for p in ps:
        for b in bs:
            ei=pd.read_csv('expected output/results/Figure11_12_A3/efficiency change after cascading p='+str(p)+' b='+str(b)+'.csv',names=['port','efficiency initial','apart node','efficiency after'])
            wei=pd.read_csv('expected output/results/Figure11_12_A3/weight efficiency change after cascading p='+str(p)+' b='+str(b)+'.csv',names=['port','efficiency initial','apart node','efficiency after'])
            ei['delta E']=(ei['efficiency after']-ei['efficiency initial'])/ei['efficiency initial']
            wei['delta E']=(wei['efficiency after']-wei['efficiency initial'])/wei['efficiency initial']
            ce=ei.groupby(by='apart node')['delta E'].sum()
            wce=wei.groupby(by='apart node')['delta E'].sum()
            ve=ei.groupby(by='port')['delta E'].sum()
            wve=wei.groupby(by='port')['delta E'].sum()
            ce.to_csv('expected output/results/Figure13_14/criticality p='+str(p)+' b='+str(b)+'.csv')
            wce.to_csv('expected output/results/Figure13_14/weight criticality p='+str(p)+' b='+str(b)+'.csv')
            ve.to_csv('expected output/results/Figure13_14/vulnerability p='+str(p)+' b='+str(b)+'.csv')
            wve.to_csv('expected output/results/Figure13_14/weight vulnerability p='+str(p)+' b='+str(b)+'.csv')




